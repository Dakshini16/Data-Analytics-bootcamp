{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "337578f7-77ed-4640-a599-601c761d602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c3f6a1-695b-47dc-88c5-e102f0f6bd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Amazon robots.txt ---\n",
      "\n",
      "User-agent: *\n",
      "Disallow: /exec/obidos/account-access-login\n",
      "Disallow: /exec/obidos/change-style\n",
      "Disallow: /exec/obidos/flex-sign-in\n",
      "Disallow: /exec/obidos/handle-buy-box\n",
      "Disallow: /exec/obidos/tg/cm/member/\n",
      "Disallow: /gp/aw/help/id=sss\n",
      "Disallow: /gp/cart\n",
      "Disallow: /gp/flex\n",
      "Disallow: /gp/product/e-mail-friend\n",
      "Disallow: /gp/product/product-availability\n",
      "Disallow: /gp/product/rate-this-item\n",
      "Disallow: /gp/sign-in\n",
      "Disallow: /gp/reader\n",
      "Disallow: /gp/sitbv3/reader\n",
      "Disallow: /gp/richpub/syltguides/create\n",
      "D\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- ESPNCricInfo robots.txt ---\n",
      "\n",
      "Failed to retrieve https://www.espncricinfo.com/robots.txt (Status Code: 403)\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Instagram robots.txt ---\n",
      "\n",
      "# Notice: Collection of data on Instagram through automated means is\n",
      "# prohibited unless you have express written permission from Instagram\n",
      "# and may only be conducted for the limited purpose contained in said\n",
      "# permission.\n",
      "# All authorized user-agents listed on this page must comply with Meta’s\n",
      "# Automated Data Collection Terms available at:\n",
      "# https://www.facebook.com/legal/automated_data_collection_terms\n",
      "User-agent: Amazonbot\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Applebot-Extended\n",
      "Disallow: /\n",
      "\n",
      "User-agent: \n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URLs of robots.txt files\n",
    "urls = {\n",
    "    \"Amazon\": \"https://www.amazon.com/robots.txt\",\n",
    "    \"ESPNCricInfo\": \"https://www.espncricinfo.com/robots.txt\",\n",
    "    \"Instagram\": \"https://www.instagram.com/robots.txt\"\n",
    "}\n",
    "\n",
    "# Function to fetch robots.txt content\n",
    "def fetch_robots(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return f\"Failed to retrieve {url} (Status Code: {response.status_code})\"\n",
    "\n",
    "# Fetch and store robots.txt contents\n",
    "robots_data = {site: fetch_robots(url) for site, url in urls.items()}\n",
    "\n",
    "# Print results\n",
    "for site, data in robots_data.items():\n",
    "    print(f\"--- {site} robots.txt ---\\n\")\n",
    "    print(data[:500])  # Print only the first 500 characters for readability\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175cc8e4-6ec8-48c8-a765-5fa288bf4471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Amazon Analysis ---\n",
      "User-agents: ['*', 'EtaoSpider', 'GPTBot', 'CCBot']\n",
      "Disallowed Paths: ['/exec/obidos/account-access-login', '/exec/obidos/change-style', '/exec/obidos/flex-sign-in', '/exec/obidos/handle-buy-box', '/exec/obidos/tg/cm/member/']\n",
      "Allowed Paths: ['/wishlist/universal*', '/wishlist/vendor-button*', '/wishlist/get-button*', '/gp/wishlist/universal*', '/gp/wishlist/vendor-button*']\n",
      "Crawl-delay: None\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- ESPNCricInfo Analysis ---\n",
      "User-agents: []\n",
      "Disallowed Paths: []\n",
      "Allowed Paths: []\n",
      "Crawl-delay: None\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Instagram Analysis ---\n",
      "User-agents: ['Amazonbot', 'Applebot-Extended', 'ClaudeBot', 'Google-Extended', 'GPTBot']\n",
      "Disallowed Paths: ['/', '/', '/', '/', '/']\n",
      "Allowed Paths: []\n",
      "Crawl-delay: None\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to parse robots.txt\n",
    "def parse_robots(txt):\n",
    "    rules = {\"User-agent\": [], \"Disallow\": [], \"Allow\": [], \"Crawl-delay\": None}\n",
    "    \n",
    "    for line in txt.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"User-agent:\"):\n",
    "            rules[\"User-agent\"].append(line.split(\":\")[1].strip())\n",
    "        elif line.startswith(\"Disallow:\"):\n",
    "            rules[\"Disallow\"].append(line.split(\":\")[1].strip())\n",
    "        elif line.startswith(\"Allow:\"):\n",
    "            rules[\"Allow\"].append(line.split(\":\")[1].strip())\n",
    "        elif line.startswith(\"Crawl-delay:\"):\n",
    "            rules[\"Crawl-delay\"] = line.split(\":\")[1].strip()\n",
    "    \n",
    "    return rules\n",
    "\n",
    "# Parse the fetched robots.txt files\n",
    "parsed_robots = {site: parse_robots(data) for site, data in robots_data.items()}\n",
    "\n",
    "# Print summary\n",
    "for site, rules in parsed_robots.items():\n",
    "    print(f\"--- {site} Analysis ---\")\n",
    "    print(f\"User-agents: {rules['User-agent'][:5]}\")  # Show first 5 user-agents\n",
    "    print(f\"Disallowed Paths: {rules['Disallow'][:5]}\")  # Show first 5 disallowed paths\n",
    "    print(f\"Allowed Paths: {rules['Allow'][:5]}\")  # Show first 5 allowed paths\n",
    "    print(f\"Crawl-delay: {rules['Crawl-delay']}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c0346a-0506-4d0d-a41a-aea21da3b54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Amazon Terms of Use ---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Terms of Use | Sell on Amazon\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Seller LoginBackStartBackSell onlineHow to register as a sellerHow to sell on Amazon.inHow to list a productOffers for new sellersGrowBackGrow your businessGrow your businessTools to grow your businessAmazon selling programsSell globallyService Provider NetworkLaunch your brandPricingBackPricingType of feesCompare fulfilment channelsResourcesBackResourcesLearnGet helpSell on Amazon blogsStart Selling✕Select your preferred languageEnglish - INहिंदी - INதமிழ் - INಕನ್ನಡ - INमराठी - INગુજરાતી - INবাংলা - INമലയാളം - INతెలుగు - INTerms of UseWelcome to the website sell.amazon.in (\"Sell on Amazon\"). The website Sell on Amazon is operated by Amazon Seller Services Private Limited (\"Amazon\" or \"us\" or \"we\" or \"our\"), having its registered office located 8th Floor, Brigade Gateway 26/1 Dr. Rajkumar Road Bangalore – 560055, Karnataka, India. Please read the Conditions of Use document carefully before using the Sell on Amazon website. By visitin\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- ESPNCricInfo Terms of Use ---\n",
      "\n",
      "Failed to retrieve https://www.espncricinfo.com/ci/content/site/company/terms_use.html (Status Code: 403)\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Instagram Terms of Use ---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Help Center\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Example function to fetch and parse Terms of Use\n",
    "def fetch_terms(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        return soup.get_text()[:1000]  # Print first 1000 characters for readability\n",
    "    else:\n",
    "        return f\"Failed to retrieve {url} (Status Code: {response.status_code})\"\n",
    "\n",
    "terms_urls = {\n",
    "    \"Amazon\": \"https://sell.amazon.in/bn/standards/terms-of-use\",\n",
    "    \"ESPNCricInfo\": \"https://www.espncricinfo.com/ci/content/site/company/terms_use.html\",\n",
    "    \"Instagram\": \"https://help.instagram.com/581066165581870\"\n",
    "}\n",
    "\n",
    "terms_data = {site: fetch_terms(url) for site, url in terms_urls.items()}\n",
    "\n",
    "# Print summary\n",
    "for site, data in terms_data.items():\n",
    "    print(f\"--- {site} Terms of Use ---\\n\")\n",
    "    print(data[:1000])  # Print first 1000 characters\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db9707eb-847e-4ada-94f5-5131d53e5d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"robots_analysis.txt\", \"w\") as file:\n",
    "    for site, rules in parsed_robots.items():\n",
    "        file.write(f\"--- {site} Analysis ---\\n\")\n",
    "        file.write(f\"User-agents: {rules['User-agent'][:5]}\\n\")\n",
    "        file.write(f\"Disallowed Paths: {rules['Disallow'][:5]}\\n\")\n",
    "        file.write(f\"Allowed Paths: {rules['Allow'][:5]}\\n\")\n",
    "        file.write(f\"Crawl-delay: {rules['Crawl-delay']}\\n\")\n",
    "        file.write(\"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819bea71-9d9f-4c1e-95d3-0aff680adbae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
